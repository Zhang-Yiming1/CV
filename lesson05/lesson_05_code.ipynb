{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_input, n_output, n_units):\n",
    "    # encoder\n",
    "    encoder_input = Input(shape=(None, n_input))\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    _,encoder_h, encoder_c = encoder(encoder_input)\n",
    "    encoder_state = [encoder_h, encoder_c]\n",
    "    \n",
    "    \n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_input = Input(shape=(None, n_output))\n",
    "    decoder = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_output, _, _ = decoder(decoder_input,\n",
    "                                   initial_state=encoder_state)\n",
    "    decoder_dense = Dense(n_output, activation='softmax')\n",
    "    decoder_output = decoder_dense(decoder_output)\n",
    "    \n",
    "    # Define the model \n",
    "    model = Model([encoder_input, decoder_input], decoder_output)\n",
    "    \n",
    "    # inference setup\n",
    "    # encoder\n",
    "    encoder_infer = Model(encoder_input, encoder_state)\n",
    "    \n",
    "    # decoder\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))    \n",
    "    decoder_state_input = [decoder_state_input_h, decoder_state_input_c] \n",
    "    \n",
    "    decoder_infer_output, decoder_infer_state_h, decoder_infer_state_c = decoder(decoder_input,\n",
    "                                                                                 initial_state=decoder_state_input)\n",
    "    decoder_infer_state = [decoder_infer_state_h, decoder_infer_state_c]\n",
    "    decoder_infer_output = decoder_dense(decoder_infer_output)\n",
    "    \n",
    "    decoder_infer = Model([decoder_input] + decoder_state_input,\n",
    "                          [decoder_infer_output] + decoder_infer_state)\n",
    "    \n",
    "    return model, encoder_infer, decoder_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_UNITS = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 50\n",
    "NUM_SAMPLES = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据下载\n",
    "[下载地址](http://www.manythings.org/anki/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'cmn-eng/cmn.txt'\n",
    "df = pd.read_table(data_path,header=None).iloc[:NUM_SAMPLES,:,]\n",
    "df.columns=['inputs', 'targets', 'others']\n",
    "\n",
    "df['targets'] = df['targets'].apply(lambda x: '\\t'+x+'\\n')\n",
    "\n",
    "input_texts = df.inputs.values.tolist()\n",
    "target_texts = df.targets.values.tolist()\n",
    "\n",
    "input_characters = sorted(list(set(df.inputs.unique().sum())))\n",
    "target_characters = sorted(list(set(df.targets.unique().sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INUPT_LENGTH = max([len(i) for i in input_texts])\n",
    "OUTPUT_LENGTH = max([len(i) for i in target_texts])\n",
    "INPUT_FEATURE_LENGTH = len(input_characters)\n",
    "OUTPUT_FEATURE_LENGTH = len(target_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.zeros((NUM_SAMPLES, INUPT_LENGTH, INPUT_FEATURE_LENGTH))\n",
    "decoder_input = np.zeros((NUM_SAMPLES, OUTPUT_LENGTH, OUTPUT_FEATURE_LENGTH))\n",
    "decoder_output = np.zeros((NUM_SAMPLES, OUTPUT_LENGTH, OUTPUT_FEATURE_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {char:index for index,char in enumerate(input_characters)}\n",
    "input_dict_reverse = {index:char for index,char in enumerate(input_characters)}\n",
    "target_dict = {char:index for index,char in enumerate(target_characters)}\n",
    "target_dict_reverse = {index:char for index,char in enumerate(target_characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index,seq in enumerate(input_texts):\n",
    "    for char_index, char in enumerate(seq):\n",
    "        encoder_input[seq_index, char_index, input_dict[char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index,seq in enumerate(target_texts):\n",
    "    for char_index,char in enumerate(seq):\n",
    "        decoder_input[seq_index,char_index, target_dict[char]] = 1.0\n",
    "        if char_index > 0:\n",
    "            decoder_output[seq_index,char_index-1, target_dict[char]] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 观察向量化的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([input_dict_reverse[np.argmax(i)] for i in encoder_input[0] if max(i) !=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'嗨。\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([target_dict_reverse[np.argmax(i)] for i in decoder_output[0] if max(i) !=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train, encoder_infer, decoder_infer = create_model(INPUT_FEATURE_LENGTH,\n",
    "                                                         OUTPUT_FEATURE_LENGTH,\n",
    "                                                         N_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile & run training\n",
    "model_train.compile(optimizer='rmsprop',\n",
    "                    loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 72)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 2561)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 336896      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  2885632     input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2561)   658177      lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,880,705\n",
      "Trainable params: 3,880,705\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 72)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 256), (None, 256) 336896    \n",
      "=================================================================\n",
      "Total params: 336,896\n",
      "Trainable params: 336,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_infer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 2561)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  2885632     input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2561)   658177      lstm_2[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,543,809\n",
      "Trainable params: 3,543,809\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_infer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.2\n",
    "model_train.fit([encoder_input,decoder_input],\n",
    "                decoder_output,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCH,\n",
    "                validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_chinese(source,encoder_inference, decoder_inference, n_steps, features):\n",
    "    state = encoder_inference.predict(source)\n",
    "    predict_seq = np.zeros((1,1,features))\n",
    "    predict_seq[0,0,target_dict['\\t']] = 1\n",
    "\n",
    "    output = ''\n",
    "\n",
    "    for i in range(n_steps): # n_steps为句子最大长度\n",
    "        yhat,h,c = decoder_inference.predict([predict_seq]+state)\n",
    "        char_index = np.argmax(yhat[0,-1,:])\n",
    "        char = target_dict_reverse[char_index]\n",
    "        output += char\n",
    "        state = [h,c]\n",
    "        predict_seq = np.zeros((1,1,features))\n",
    "        predict_seq[0,0,char_index] = 1\n",
    "        if char == '\\n':\n",
    "            break\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop grumbling.\n",
      "别再念了。\n",
      "\n",
      "Stop resisting!\n",
      "别再念了。\n",
      "\n",
      "Summer is over.\n",
      "生活很久。\n",
      "\n",
      "Take your time.\n",
      "你不要说话，我。\n",
      "\n",
      "Take your time.\n",
      "你不要说话，我。\n",
      "\n",
      "That was wrong.\n",
      "那不好。\n",
      "\n",
      "That's a shame.\n",
      "那是一個好主意。\n",
      "\n",
      "That's logical.\n",
      "那太好了。\n",
      "\n",
      "That's my coat.\n",
      "那是我的錯。\n",
      "\n",
      "That's perfect.\n",
      "那是一個好主意。\n",
      "\n",
      "That's too bad.\n",
      "那是不好。\n",
      "\n",
      "That's too bad.\n",
      "那是不好。\n",
      "\n",
      "That's too bad.\n",
      "那是不好。\n",
      "\n",
      "The birds sang.\n",
      "這個男人吃了麵包。\n",
      "\n",
      "The flag is up.\n",
      "火车准时到了。\n",
      "\n",
      "The phone rang.\n",
      "這個男人吃了麵包。\n",
      "\n",
      "Their eyes met.\n",
      "他們的車子很起。\n",
      "\n",
      "These are pens.\n",
      "這些是筆。\n",
      "\n",
      "They hated Tom.\n",
      "他們不會工作。\n",
      "\n",
      "They have jobs.\n",
      "他们没有。\n",
      "\n",
      "They let me go.\n",
      "他們不會見。\n",
      "\n",
      "They love that.\n",
      "他们不喜欢你。\n",
      "\n",
      "They trust Tom.\n",
      "他們會幫助。\n",
      "\n",
      "They want more.\n",
      "他们不喜欢你。\n",
      "\n",
      "They want this.\n",
      "他们不喜欢你。\n",
      "\n",
      "They were good.\n",
      "他們是我的。\n",
      "\n",
      "This is a book.\n",
      "这是一个好大的时间。\n",
      "\n",
      "This is my bag.\n",
      "这是我的自行车。\n",
      "\n",
      "Tom can change.\n",
      "汤姆不会游泳。\n",
      "\n",
      "Tom can't swim.\n",
      "汤姆不会游泳。\n",
      "\n",
      "Tom has a plan.\n",
      "湯姆有個好人。\n",
      "\n",
      "Tom is a rabbi.\n",
      "汤姆是个好主意。\n",
      "\n",
      "Tom is no fool.\n",
      "汤姆是个好人。\n",
      "\n",
      "Tom isn't dumb.\n",
      "汤姆不傻。\n",
      "\n",
      "Tom looks pale.\n",
      "湯姆喜歡這個。\n",
      "\n",
      "Tom loves dogs.\n",
      "湯姆喜歡這個。\n",
      "\n",
      "Tom turned red.\n",
      "汤姆走得很慢。\n",
      "\n",
      "Tom walked out.\n",
      "湯姆喜歡這個。\n",
      "\n",
      "Tom was crying.\n",
      "湯姆有個好人。\n",
      "\n",
      "Tom won't stop.\n",
      "湯姆不會停。\n",
      "\n",
      "Tom's fearless.\n",
      "汤姆的手手。\n",
      "\n",
      "Tom's laughing.\n",
      "汤姆的手手。\n",
      "\n",
      "Tom's thrilled.\n",
      "汤姆不傻。\n",
      "\n",
      "Turn on the TV.\n",
      "打电话回家。\n",
      "\n",
      "Turn up the TV.\n",
      "把电视声音调大点儿。\n",
      "\n",
      "Was Tom asleep?\n",
      "汤姆说了吗？\n",
      "\n",
      "Wash your feet.\n",
      "洗你的脚。\n",
      "\n",
      "Wash your feet.\n",
      "洗你的脚。\n",
      "\n",
      "Watch yourself.\n",
      "在家裡下我的路子！\n",
      "\n",
      "We forgive you.\n",
      "我們在這裡。\n",
      "\n",
      "We knew no one.\n",
      "我们需要一辆新护。\n",
      "\n",
      "We need a hero.\n",
      "我们需要一辆新护。\n",
      "\n",
      "We study music.\n",
      "我們很多就就到了。\n",
      "\n",
      "We were robbed.\n",
      "我们是个好人。\n",
      "\n",
      "We'll continue.\n",
      "我们想要一下。\n",
      "\n",
      "We're a family.\n",
      "我們是個好人。\n",
      "\n",
      "We're not late.\n",
      "我们不在这里。\n",
      "\n",
      "Well, let's go.\n",
      "好吧，我們走吧。\n",
      "\n",
      "Were you right?\n",
      "你是學生嗎？\n",
      "\n",
      "What about you?\n",
      "你想要什么？\n",
      "\n",
      "What about you?\n",
      "你想要什么？\n",
      "\n",
      "What do you do?\n",
      "你想要什么？\n",
      "\n",
      "What's her job?\n",
      "那是什么？\n",
      "\n",
      "Where do we go?\n",
      "我们去哪里？\n",
      "\n",
      "Where were you?\n",
      "你在哪裡打網?\n",
      "\n",
      "Who's that guy?\n",
      "我们谁在这里工作？\n",
      "\n",
      "Who's that man?\n",
      "那是谁？\n",
      "\n",
      "Why do you ask?\n",
      "你为什么哭？\n",
      "\n",
      "Why is he here?\n",
      "为什么我在这儿？\n",
      "\n",
      "Wipe your eyes.\n",
      "你们的不是么的。\n",
      "\n",
      "Yes, I know it.\n",
      "是的，我有一個好主意。\n",
      "\n",
      "Yes, of course.\n",
      "是的，當然。\n",
      "\n",
      "You look bored.\n",
      "你看起来很困了。\n",
      "\n",
      "You look tense.\n",
      "你看起来很困了。\n",
      "\n",
      "You look tired.\n",
      "你看起来很困了。\n",
      "\n",
      "You look tired.\n",
      "你看起来很困了。\n",
      "\n",
      "You must do it.\n",
      "你可以相信她。\n",
      "\n",
      "You'll love it.\n",
      "你会需要。\n",
      "\n",
      "You're kidding!\n",
      "你在这里。\n",
      "\n",
      "You're welcome.\n",
      "你真是太好了。\n",
      "\n",
      "A man must work.\n",
      "請我一個問題。\n",
      "\n",
      "Are you friends?\n",
      "你是个好人吗？\n",
      "\n",
      "Are you kidding?\n",
      "你在哭嗎？\n",
      "\n",
      "Are you over 18?\n",
      "你是學生嗎？\n",
      "\n",
      "Are you serious?\n",
      "你是个好人吗？\n",
      "\n",
      "Are you thirsty?\n",
      "你是个好人吗？\n",
      "\n",
      "Balls are round.\n",
      "把它放下。\n",
      "\n",
      "Be happy for me.\n",
      "把你的東西放了。\n",
      "\n",
      "Behave yourself.\n",
      "把你的東西放了。\n",
      "\n",
      "Black suits you.\n",
      "把它放在桌子。\n",
      "\n",
      "Boil some water.\n",
      "把你的想法好。\n",
      "\n",
      "Call the police!\n",
      "打电话回家！\n",
      "\n",
      "Call the police!\n",
      "打电话回家！\n",
      "\n",
      "Call the police.\n",
      "打開收音机。\n",
      "\n",
      "Can you find it?\n",
      "你能幫嗎？\n",
      "\n",
      "Can you help me?\n",
      "你能幫我嗎？\n",
      "\n",
      "Can you help me?\n",
      "你能幫我嗎？\n",
      "\n",
      "Can you help us?\n",
      "你能幫我嗎？\n",
      "\n",
      "Clean your room.\n",
      "你們的都是真的。\n",
      "\n",
      "Clean your room.\n",
      "你們的都是真的。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000,1100):\n",
    "    test = encoder_input[i:i+1,:,:] \n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    print(input_texts[i])\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
